{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7cb3e8a-da1d-49e2-858d-c618b98e66b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from fvgp import GP\n",
    "from fvgp.gp_kernels import squared_exponential_kernel, matern_kernel_diff2, exponential_kernel\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b045e1d-3548-45f8-8537-6ddfe2f0ccc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load digits dataset\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2f4df0d-8cf9-4c36-969f-7800a42131ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse = X_train[::5]\n",
    "X_test_sparse = X_test[::5]\n",
    "y_train_sparse = y_train[::5]\n",
    "y_test_sparse = y_test[::5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1c99fc4-5501-4f79-ac28-371e8bfdf26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d03aade-c695-40d5-92d4-5bba77e32dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_sparse)\n",
    "X_test_scaled = scaler.transform(X_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b97c7148-ce07-44ae-a543-36acbb4b271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_1d_slice(x1, x2):\n",
    "    # Project onto 1D slice (e.g., the first dimension)\n",
    "    slice_x1 = x1[:, 0]  # Use the first feature/column for slicing\n",
    "    slice_x2 = x2[:, 0]\n",
    "    return wasserstein_distance(slice_x1, slice_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f96e7c3-cb0d-4a0c-b6fd-6a21d8591511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_exponential_kernel(x1, x2, length_scale):\n",
    "    distance = np.array([wasserstein_1d_slice(x1[i:i+1], x2[j:j+1]) for i in range(x1.shape[0]) for j in range(x2.shape[0])])\n",
    "    distance = distance.reshape(x1.shape[0], x2.shape[0])\n",
    "    return np.exp(-distance / length_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4de9f57-8fd7-4acf-a87f-ab930f8883ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_model = GP(\n",
    "    X_train_scaled,\n",
    "    y_train_sparse,\n",
    "    init_hyperparameters=np.array([1.0]),  # Initialize with a length scale of 1.0\n",
    "    gp_kernel_function=wasserstein_exponential_kernel,\n",
    "    noise_variances=np.ones(y_train_sparse.shape) * 0.01  # Assuming small noise variance (measurement error)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ebea07eb-fee5-4424-9a85-fa8bbb1fec74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.63727006])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hps_bounds = np.array([[0.1, 10.0]])\n",
    "\n",
    "# Train the GP model using MCMC with 100 iterations\n",
    "gp_model.train(\n",
    "    hyperparameter_bounds=hps_bounds,\n",
    "    method='mcmc',  # Use MCMC for hyperparameter sampling\n",
    "    max_iter=100,  # Run MCMC for 100 iterations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fede2320-e9f5-4031-b8b7-b0526d854277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.19      1.00      0.33         7\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         6\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.19        36\n",
      "   macro avg       0.02      0.10      0.03        36\n",
      "weighted avg       0.04      0.19      0.06        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "posterior = gp_model.posterior_mean(X_test_scaled)  # Predict posterior mean\n",
    "predicted_mean = posterior[\"f(x)\"].flatten()  # Get the predicted mean for each test point\n",
    "\n",
    "# For classification, use a threshold or take the sign\n",
    "predicted_labels = np.where(predicted_mean > 0.5, 1, 0)  # Apply threshold of 0.5 for binary classification\n",
    "\n",
    "# Generate classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_sparse, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157b3afc-9b30-4495-ad8b-c6f4d752e2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6dec4bc-8683-456e-aedf-31a350e9ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kernel_matrix(X, kernel_function, length_scale, jitter=1e-6):\n",
    "    n = X.shape[0]\n",
    "    K = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            K[i, j] = kernel_function(X[i:i+1], X[j:j+1], length_scale)\n",
    "            K[j, i] = K[i, j]  # Ensure symmetry\n",
    "    # Add jitter to the diagonal\n",
    "    K += np.eye(n) * jitter\n",
    "    return K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7be9cde-e6a5-4629-8cc5-95bc86c7be0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_psd(matrix):\n",
    "    eigenvalues = np.linalg.eigvals(matrix)\n",
    "    return np.all(eigenvalues >= 0), eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd23ad2c-1541-4c19-8d8e-0bad1588f4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The kernel matrix is positive semi-definite. Median Eigenvalue: 1.0000009999999993\n"
     ]
    }
   ],
   "source": [
    "# Compute the kernel matrix for the first 100 samples as an example\n",
    "length_scale = 1.0  # Use an appropriate length scale value\n",
    "K = compute_kernel_matrix(X_train_sparse[:100], wasserstein_exponential_kernel, length_scale)\n",
    "\n",
    "# Check if the matrix is PSD\n",
    "is_positive_semi_definite, eigenvalues = is_psd(K)\n",
    "\n",
    "if is_positive_semi_definite:\n",
    "    print(\"The kernel matrix is positive semi-definite. Median Eigenvalue:\", eigenvalues.mean())\n",
    "else:\n",
    "    print(\"The kernel matrix is not positive semi-definite. Smallest eigenvalue:\", eigenvalues.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36f7eec-9d4b-40ab-bd34-cbf117200da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8bafb1-49ae-4b0e-9703-f7fdb5fb3d08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f7a9a2-5426-493e-87f9-821c4852a02c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ee7e26c-afdc-4800-a8de-35bce7407ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_exponential_kernel(x1, x2, hyperparameters):\n",
    "    length_scale = hyperparameters[0]  # Extract the length scale from hyperparameters\n",
    "    distance = np.array([wasserstein_1d_slice(x1[i:i+1], x2[j:j+1]) for i in range(x1.shape[0]) for j in range(x2.shape[0])])\n",
    "    distance = distance.reshape(x1.shape[0], x2.shape[0])\n",
    "    return np.exp(-distance / length_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b0f2d11e-551a-40c0-b93f-7bbb293ada2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10  # Digits 0-9\n",
    "gp_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f627d252-7a48-4629-a3c7-444a9c364145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GP model for class 0\n",
      "Training GP model for class 1\n",
      "Training GP model for class 2\n",
      "Training GP model for class 3\n",
      "Training GP model for class 4\n",
      "Training GP model for class 5\n",
      "Training GP model for class 6\n",
      "Training GP model for class 7\n",
      "Training GP model for class 8\n",
      "Training GP model for class 9\n"
     ]
    }
   ],
   "source": [
    "for class_label in range(num_classes):\n",
    "    print(f\"Training GP model for class {class_label}\")\n",
    "    \n",
    "    # Convert the labels to binary for the current class (1 for class_label, 0 for the rest)\n",
    "    y_train_binary = (y_train_sparse == class_label).astype(int)\n",
    "    \n",
    "    # Initialize the GP model for each class\n",
    "    gp_model = GP(\n",
    "        X_train_scaled,\n",
    "        y_train_binary,\n",
    "        init_hyperparameters=np.array([1.0]),  # Initialize with a length scale of 1.0\n",
    "        gp_kernel_function=wasserstein_exponential_kernel,\n",
    "        noise_variances=np.ones(y_train_binary.shape) * 0.01  # Assuming small noise variance (measurement error)\n",
    "    )\n",
    "\n",
    "    # Train the GP model using MCMC with 100 iterations\n",
    "    gp_model.train(\n",
    "        hyperparameter_bounds=np.array([[0.1, 10.0]]),  # Length scale bounds\n",
    "        method='mcmc',  # Use MCMC for hyperparameter sampling\n",
    "        max_iter=100,  # Run MCMC for 100 iterations\n",
    "    )\n",
    "    \n",
    "    # Store the trained GP model\n",
    "    gp_models.append(gp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3df5cebc-f2a1-486b-aad8-f568b2627525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probs(X_test, gp_models):\n",
    "    means = np.zeros((X_test.shape[0], len(gp_models)))\n",
    "    for class_label, gp_model in enumerate(gp_models):\n",
    "        posterior_rbf = gp_model.posterior_mean(X_test)  # Use posterior_mean\n",
    "        mean = posterior_rbf[\"f(x)\"]  # Access the mean predictions\n",
    "        means[:, class_label] = mean.flatten()\n",
    "    return softmax(means.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02b44914-fe2f-4a01-b661-d84c54bf427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a0994366-a0cf-4c7d-a2d0-4e6f29e2091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_probabilities = predict_probs(X_test_scaled, gp_models)\n",
    "gp_predictions = np.argmax(gp_probabilities, axis=1)\n",
    "gp_accuracy = accuracy_score(y_test_sparse, gp_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a9815df0-36ca-43d0-90c1-fe3f6a7ab2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP Classifier – Accuracy: 19.44%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.19      1.00      0.33         7\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         6\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.19        36\n",
      "   macro avg       0.02      0.10      0.03        36\n",
      "weighted avg       0.04      0.19      0.06        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(f'GP Classifier – Accuracy: {gp_accuracy * 100:.2f}%\\n')\n",
    "print(classification_report(y_test_sparse, gp_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "32cdbbc6-3f37-45a1-990d-74f7ed68e033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(X_test, gp_models):\n",
    "    num_samples = X_test.shape[0]\n",
    "    num_classes = len(gp_models)\n",
    "    class_probs = np.zeros((num_samples, num_classes))  # Store probabilities for each class\n",
    "    \n",
    "    for class_label, gp_model in enumerate(gp_models):\n",
    "        # Get the posterior mean for each test sample\n",
    "        posterior = gp_model.posterior_mean(X_test)\n",
    "        class_probs[:, class_label] = posterior[\"f(x)\"].flatten()  # Get the predicted mean\n",
    "    \n",
    "    # For each sample, choose the class with the highest probability\n",
    "    predicted_classes = np.argmax(class_probs, axis=1)\n",
    "    \n",
    "    return predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a29c305a-6099-47ae-a0d2-29db03b9636b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP Classifier – Accuracy: 19.44%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.19      1.00      0.33         7\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         6\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.19        36\n",
      "   macro avg       0.02      0.10      0.03        36\n",
      "weighted avg       0.04      0.19      0.06        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "gp_predictions = predict_class(X_test_scaled, gp_models)\n",
    "gp_accuracy = accuracy_score(y_test_sparse, gp_predictions)\n",
    "\n",
    "# Print the classification report and accuracy\n",
    "print(f'GP Classifier – Accuracy: {gp_accuracy * 100:.2f}%\\n')\n",
    "print(classification_report(y_test_sparse, gp_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36a505e-c822-4cb1-9518-3b4f61b89534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
